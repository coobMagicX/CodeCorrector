{"close": "    public void close() throws IOException {\n        is.close();\n    }", "getRecordSize": "    public int getRecordSize() {\n        return recordSize;\n    }", "available": "    public int available() throws IOException {\n        if (isDirectory()) {\n            return 0;\n        }\n        if (entrySize - entryOffset > Integer.MAX_VALUE) {\n            return Integer.MAX_VALUE;\n        }\n        return (int) (entrySize - entryOffset);\n    }", "skip": "    public long skip(final long n) throws IOException {\n        if (n <= 0 || isDirectory()) {\n            return 0;\n        }\n\n        final long available = entrySize - entryOffset;\n        final long skipped = is.skip(Math.min(n, available)); \n        count(skipped);\n        entryOffset += skipped;\n        return skipped;\n    }", "mark": "    public void mark(final int markLimit) {\n    }", "reset": "    public synchronized void reset() {\n    }", "skipRecordPadding": "    private void skipRecordPadding() throws IOException {\n        if (!isDirectory() && this.entrySize > 0 && this.entrySize % this.recordSize != 0) {\n            final long numRecords = (this.entrySize / this.recordSize) + 1;\n            final long padding = (numRecords * this.recordSize) - this.entrySize;\n            final long skipped = IOUtils.skip(is, padding);\n            count(skipped);\n        }\n    }", "isEOFRecord": "    protected boolean isEOFRecord(final byte[] record) {\n        return record == null || ArchiveUtils.isArrayZero(record, recordSize);\n    }", "readRecord": "    protected byte[] readRecord() throws IOException {\n\n        final byte[] record = new byte[recordSize];\n\n        final int readNow = IOUtils.readFully(is, record);\n        count(readNow);\n        if (readNow != recordSize) {\n            return null;\n        }\n\n        return record;\n    }", "readGlobalPaxHeaders": "    private void readGlobalPaxHeaders() throws IOException {\n        globalPaxHeaders = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n    }", "paxHeaders": "    private void paxHeaders() throws IOException{\n        final Map<String, String> headers = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n        applyPaxHeadersToCurrentEntry(headers);\n    }", "parsePaxHeaders": "    Map<String, String> parsePaxHeaders(final InputStream i)\n        throws IOException {\n        final Map<String, String> headers = new HashMap<String, String>(globalPaxHeaders);\n        // Format is \"length keyword=value\\n\";\n        while(true){ // get length\n            int ch;\n            int len = 0;\n            int read = 0;\n            while((ch = i.read()) != -1) {\n                read++;\n                if (ch == ' '){\n                    // Get keyword\n                    final ByteArrayOutputStream coll = new ByteArrayOutputStream();\n                    while((ch = i.read()) != -1) {\n                        read++;\n                        if (ch == '='){ // end of keyword\n                            final String keyword = coll.toString(CharsetNames.UTF_8);\n                            // Get rest of entry\n                            final int restLen = len - read;\n                            if (restLen == 1) { // only NL\n                                headers.remove(keyword);\n                            } else {\n                                final byte[] rest = new byte[restLen];\n                                final int got = IOUtils.readFully(i, rest);\n                                if (got != restLen) {\n                                    throw new IOException(\"Failed to read \"\n                                                          + \"Paxheader. Expected \"\n                                                          + restLen\n                                                          + \" bytes, read \"\n                                                          + got);\n                                }\n                                // Drop trailing NL\n                                final String value = new String(rest, 0,\n                                                          restLen - 1, CharsetNames.UTF_8);\n                                headers.put(keyword, value);\n                            }\n                            break;\n                        }\n                        coll.write((byte) ch);\n                    }\n                    break; // Processed single header\n                }\n                len *= 10;\n                len += ch - '0';\n            }\n            if (ch == -1){ // EOF\n                break;\n            }\n        }\n        return headers;\n    }", "applyPaxHeadersToCurrentEntry": "    private void applyPaxHeadersToCurrentEntry(final Map<String, String> headers) {\n        /*\n         * The following headers are defined for Pax.\n         * atime, ctime, charset: cannot use these without changing TarArchiveEntry fields\n         * mtime\n         * comment\n         * gid, gname\n         * linkpath\n         * size\n         * uid,uname\n         * SCHILY.devminor, SCHILY.devmajor: don't have setters/getters for those\n         *\n         * GNU sparse files use additional members, we use\n         * GNU.sparse.size to detect the 0.0 and 0.1 versions and\n         * GNU.sparse.realsize for 1.0.\n         *\n         * star files use additional members of which we use\n         * SCHILY.filetype in order to detect star sparse files.\n         */\n        for (final Entry<String, String> ent : headers.entrySet()){\n            final String key = ent.getKey();\n            final String val = ent.getValue();\n            if (\"path\".equals(key)){\n                currEntry.setName(val);\n            } else if (\"linkpath\".equals(key)){\n                currEntry.setLinkName(val);\n            } else if (\"gid\".equals(key)){\n                currEntry.setGroupId(Long.parseLong(val));\n            } else if (\"gname\".equals(key)){\n                currEntry.setGroupName(val);\n            } else if (\"uid\".equals(key)){\n                currEntry.setUserId(Long.parseLong(val));\n            } else if (\"uname\".equals(key)){\n                currEntry.setUserName(val);\n            } else if (\"size\".equals(key)){\n                currEntry.setSize(Long.parseLong(val));\n            } else if (\"mtime\".equals(key)){\n                currEntry.setModTime((long) (Double.parseDouble(val) * 1000));\n            } else if (\"SCHILY.devminor\".equals(key)){\n                currEntry.setDevMinor(Integer.parseInt(val));\n            } else if (\"SCHILY.devmajor\".equals(key)){\n                currEntry.setDevMajor(Integer.parseInt(val));\n            } else if (\"GNU.sparse.size\".equals(key)) {\n                currEntry.fillGNUSparse0xData(headers);\n            } else if (\"GNU.sparse.realsize\".equals(key)) {\n                currEntry.fillGNUSparse1xData(headers);\n            } else if (\"SCHILY.filetype\".equals(key) && \"sparse\".equals(val)) {\n                currEntry.fillStarSparseData(headers);\n            }\n        }\n    }", "readOldGNUSparse": "    private void readOldGNUSparse() throws IOException {\n        /* we do not really process sparse files yet\n        sparses = new ArrayList();\n        sparses.addAll(currEntry.getSparses());\n        */\n        if (currEntry.isExtended()) {\n            TarArchiveSparseEntry entry;\n            do {\n                final byte[] headerBuf = getRecord();\n                if (headerBuf == null) {\n                    currEntry = null;\n                    break;\n                }\n                entry = new TarArchiveSparseEntry(headerBuf);\n                /* we do not really process sparse files yet\n                sparses.addAll(entry.getSparses());\n                */\n            } while (entry.isExtended());\n        }\n    }", "isDirectory": "    private boolean isDirectory() {\n        return currEntry != null && currEntry.isDirectory();\n    }", "read": "    public int read(final byte[] buf, final int offset, int numToRead) throws IOException {\n    \tint totalRead = 0;\n\n        if (hasHitEOF || isDirectory() || entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if (currEntry == null) {\n            throw new IllegalStateException(\"No current tar entry\");\n        }\n\n        numToRead = Math.min(numToRead, available());\n        \n        totalRead = is.read(buf, offset, numToRead);\n        \n        if (totalRead == -1) {\n            if (numToRead > 0) {\n                throw new IOException(\"Truncated TAR archive\");\n            }\n            hasHitEOF = true;\n        } else {\n            count(totalRead);\n            entryOffset += totalRead;\n        }\n\n        return totalRead;\n    }", "canReadEntryData": "    public boolean canReadEntryData(final ArchiveEntry ae) {\n        if (ae instanceof TarArchiveEntry) {\n            final TarArchiveEntry te = (TarArchiveEntry) ae;\n            return !te.isSparse();\n        }\n        return false;\n    }", "isAtEOF": "    protected final boolean isAtEOF() {\n        return hasHitEOF;\n    }", "consumeRemainderOfLastBlock": "    private void consumeRemainderOfLastBlock() throws IOException {\n        final long bytesReadOfLastBlock = getBytesRead() % blockSize;\n        if (bytesReadOfLastBlock > 0) {\n            final long skipped = IOUtils.skip(is, blockSize - bytesReadOfLastBlock);\n            count(skipped);\n        }\n    }", "matches": "    public static boolean matches(final byte[] signature, final int length) {\n        if (length < TarConstants.VERSION_OFFSET+TarConstants.VERSIONLEN) {\n            return false;\n        }\n\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_POSIX,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_POSIX,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_GNU,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            (\n             ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_SPACE,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            ||\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_ZERO,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            )\n                ){\n            return true;\n        }\n        // COMPRESS-107 - recognise Ant tar files\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_ANT,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_ANT,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        return false;\n    }"}