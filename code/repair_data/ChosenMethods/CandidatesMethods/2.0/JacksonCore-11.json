{"release": "    public void release()\n    {\n        // we will try to merge if child table has new entries\n        if (_parent != null && maybeDirty()) {\n            _parent.mergeChild(new TableInfo(this));\n            /* Let's also mark this instance as dirty, so that just in\n             * case release was too early, there's no corruption of possibly shared data.\n             */\n            _hashShared = true;\n        }\n    }", "size": "    public int size()\n    {\n        if (_tableInfo != null) { // root table\n            return _tableInfo.get().count;\n        }\n        // nope, child table\n        return _count;\n    }", "_verifyNeedForRehash": "    private void _verifyNeedForRehash() {\n        // Yes if above 80%, or above 50% AND have ~1% spill-overs\n        if (_count > (_hashSize >> 1)) { // over 50%\n            int spillCount = (_spilloverEnd - _spilloverStart()) >> 2;\n            if ((spillCount > (1 + _count >> 7))\n                    || (_count > (_hashSize * 0.80))) {\n                _needRehash = true;\n            }\n        }\n    }", "_verifySharing": "    private void _verifySharing()\n    {\n        if (_hashShared) {\n            _hashArea = Arrays.copyOf(_hashArea, _hashArea.length);\n            _names = Arrays.copyOf(_names, _names.length);\n            _hashShared = false;\n            // 09-Sep-2015, tatu: As per [jackson-core#216], also need to ensure\n            //    we rehash as needed, as need-rehash flag is not copied from parent\n        }\n        if (_needRehash) {\n            rehash();\n        }\n    }", "rehash": "    private void rehash()\n    {\n        _needRehash = false;\n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _hashShared = false;\n\n        // And then we can first deal with the main hash area. Since we are expanding\n        // linearly (double up), we know there'll be no collisions during this phase.\n        final int[] oldHashArea = _hashArea;\n        final String[] oldNames = _names;\n        final int oldSize = _hashSize;\n        final int oldCount = _count;\n        final int newSize = oldSize + oldSize;\n        final int oldEnd = _spilloverEnd;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newSize > MAX_T_SIZE) {\n            nukeSymbols(true);\n            return;\n        }\n        // double up main hash area, but do not expand long-name area:\n        _hashArea = new int[oldHashArea.length + (oldSize<<3)];\n        _hashSize = newSize;\n        _secondaryStart = (newSize << 2); // 4 ints per entry\n        _tertiaryStart = _secondaryStart + (_secondaryStart >> 1); // right after secondary\n        _tertiaryShift = _calcTertiaryShift(newSize);\n        \n        // and simply double up name array\n        _names = new String[oldNames.length << 1];\n        nukeSymbols(false);\n\n        // Plus we can scan only through the primary hash area, looking for non-empty\n        // slots, without worrying about ordering. This should never reduce priority\n        // of existing entries: primaries remain primaries; however, due to increased\n        // space, secondaries may become primaries etc\n\n        int copyCount = 0;\n        int[] q = new int[16];\n        for (int offset = 0, end = oldEnd; offset < end; offset += 4) {\n            int len = oldHashArea[offset+3];\n            if (len == 0) { // empty slot, skip\n                continue;\n            }\n            ++copyCount;\n            String name = oldNames[offset>>2];\n            switch (len) {\n            case 1:\n                q[0] = oldHashArea[offset];\n                addName(name, q, 1);\n                break;\n            case 2:\n                q[0] = oldHashArea[offset];\n                q[1] = oldHashArea[offset+1];\n                addName(name, q, 2);\n                break;\n            case 3:\n                q[0] = oldHashArea[offset];\n                q[1] = oldHashArea[offset+1];\n                q[2] = oldHashArea[offset+2];\n                addName(name, q, 3);\n                break;\n            default:\n                if (len > q.length) {\n                    q = new int[len];\n                }\n                // #0 is hash, #1 offset\n                int qoff = oldHashArea[offset+1];\n                System.arraycopy(oldHashArea, qoff, q, 0, len);\n                addName(name, q, len);\n                break;\n            }\n        }\n\n        // Sanity checks: since corruption difficult to detect, assert explicitly\n        // with production code\n        if (copyCount != oldCount) {\n            throw new IllegalStateException(\"Failed rehash(): old count=\"+oldCount+\", copyCount=\"+copyCount);\n        }\n    }"}