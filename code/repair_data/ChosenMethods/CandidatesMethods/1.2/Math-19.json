{"getStatisticsSigmaHistory": "    public List<Double> getStatisticsSigmaHistory() {\n        return statisticsSigmaHistory;\n    }", "getStatisticsMeanHistory": "    public List<RealMatrix> getStatisticsMeanHistory() {\n        return statisticsMeanHistory;\n    }", "getStatisticsFitnessHistory": "    public List<Double> getStatisticsFitnessHistory() {\n        return statisticsFitnessHistory;\n    }", "getStatisticsDHistory": "    public List<RealMatrix> getStatisticsDHistory() {\n        return statisticsDHistory;\n    }", "doOptimize": "    protected PointValuePair doOptimize() {\n        checkParameters();\n         // -------------------- Initialization --------------------------------\n        isMinimize = getGoalType().equals(GoalType.MINIMIZE);\n        final FitnessFunction fitfun = new FitnessFunction();\n        final double[] guess = fitfun.encode(getStartPoint());\n        // number of objective variables/problem dimension\n        dimension = guess.length;\n        initializeCMA(guess);\n        iterations = 0;\n        double bestValue = fitfun.value(guess);\n        push(fitnessHistory, bestValue);\n        PointValuePair optimum = new PointValuePair(getStartPoint(),\n                isMinimize ? bestValue : -bestValue);\n        PointValuePair lastResult = null;\n\n        // -------------------- Generation Loop --------------------------------\n\n        generationLoop:\n            for (iterations = 1; iterations <= maxIterations; iterations++) {\n                // Generate and evaluate lambda offspring\n                RealMatrix arz = randn1(dimension, lambda);\n                RealMatrix arx = zeros(dimension, lambda);\n                double[] fitness = new double[lambda];\n                // generate random offspring\n                for (int k = 0; k < lambda; k++) {\n                    RealMatrix arxk = null;\n                    for (int i = 0; i < checkFeasableCount+1; i++) {\n                        if (diagonalOnly <= 0) {\n                            arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k))\n                                    .scalarMultiply(sigma)); // m + sig * Normal(0,C)\n                        } else {\n                            arxk = xmean.add(times(diagD,arz.getColumnMatrix(k))\n                                    .scalarMultiply(sigma));\n                        }\n                        if (i >= checkFeasableCount || fitfun.isFeasible(arxk.getColumn(0))) {\n                            break;\n                        }\n                        // regenerate random arguments for row\n                        arz.setColumn(k, randn(dimension));\n                    }\n                    copyColumn(arxk, 0, arx, k);\n                    try {\n                        fitness[k] = fitfun.value(arx.getColumn(k)); // compute fitness\n                    } catch (TooManyEvaluationsException e) {\n                        break generationLoop;\n                    }\n                }\n                // Sort by fitness and compute weighted mean into xmean\n                int[] arindex = sortedIndices(fitness);\n                // Calculate new xmean, this is selection and recombination\n                RealMatrix xold = xmean; // for speed up of Eq. (2) and (3)\n                RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));\n                xmean = bestArx.multiply(weights);\n                RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));\n                RealMatrix zmean = bestArz.multiply(weights);\n                boolean hsig = updateEvolutionPaths(zmean, xold);\n                if (diagonalOnly <= 0) {\n                    updateCovariance(hsig, bestArx, arz, arindex, xold);\n                } else {\n                    updateCovarianceDiagonalOnly(hsig, bestArz, xold);\n                }\n                // Adapt step size sigma - Eq. (5)\n                sigma *= Math.exp(Math.min(1.0,(normps/chiN - 1.)*cs/damps));\n                double bestFitness = fitness[arindex[0]];\n                double worstFitness = fitness[arindex[arindex.length-1]];\n                if (bestValue > bestFitness) {\n                    bestValue = bestFitness;\n                    lastResult = optimum;\n                    optimum = new PointValuePair(\n                            fitfun.repairAndDecode(bestArx.getColumn(0)),\n                            isMinimize ? bestFitness : -bestFitness);\n                    if (getConvergenceChecker() != null && lastResult != null) {\n                        if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {\n                            break generationLoop;\n                        }\n                    }\n                }\n                // handle termination criteria\n                // Break, if fitness is good enough\n                if (stopFitness != 0) { // only if stopFitness is defined\n                    if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {\n                        break generationLoop;\n                    }\n                }\n                double[] sqrtDiagC = sqrt(diagC).getColumn(0);\n                double[] pcCol = pc.getColumn(0);\n                for (int i = 0; i < dimension; i++) {\n                    if (sigma*(Math.max(Math.abs(pcCol[i]), sqrtDiagC[i])) > stopTolX) {\n                        break;\n                    }\n                    if (i >= dimension-1) {\n                        break generationLoop;\n                    }\n                }\n                for (int i = 0; i < dimension; i++) {\n                    if (sigma*sqrtDiagC[i] > stopTolUpX) {\n                        break generationLoop;\n                    }\n                }\n                double historyBest = min(fitnessHistory);\n                double historyWorst = max(fitnessHistory);\n                if (iterations > 2 && Math.max(historyWorst, worstFitness) -\n                        Math.min(historyBest, bestFitness) < stopTolFun) {\n                    break generationLoop;\n                }\n                if (iterations > fitnessHistory.length &&\n                        historyWorst-historyBest < stopTolHistFun) {\n                    break generationLoop;\n                }\n                // condition number of the covariance matrix exceeds 1e14\n                if (max(diagD)/min(diagD) > 1e7) {\n                    break generationLoop;\n                }\n                // user defined termination\n                if (getConvergenceChecker() != null) {\n                    PointValuePair current =\n                        new PointValuePair(bestArx.getColumn(0),\n                                isMinimize ? bestFitness : -bestFitness);\n                    if (lastResult != null &&\n                        getConvergenceChecker().converged(iterations, current, lastResult)) {\n                        break generationLoop;\n                    }\n                    lastResult = current;\n                }\n                // Adjust step size in case of equal function values (flat fitness)\n                if (bestValue == fitness[arindex[(int)(0.1+lambda/4.)]]) {\n                    sigma = sigma * Math.exp(0.2+cs/damps);\n                }\n                if (iterations > 2 && Math.max(historyWorst, bestFitness) -\n                        Math.min(historyBest, bestFitness) == 0) {\n                    sigma = sigma * Math.exp(0.2+cs/damps);\n                }\n                // store best in history\n                push(fitnessHistory,bestFitness);\n                fitfun.setValueRange(worstFitness-bestFitness);\n                if (generateStatistics) {\n                    statisticsSigmaHistory.add(sigma);\n                    statisticsFitnessHistory.add(bestFitness);\n                    statisticsMeanHistory.add(xmean.transpose());\n                    statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));\n                }\n            }\n        return optimum;\n    }", "checkParameters": "    private void checkParameters() {\n        final double[] init = getStartPoint();\n        final double[] lB = getLowerBound();\n        final double[] uB = getUpperBound();\n\n        // Checks whether there is at least one finite bound value.\n        boolean hasFiniteBounds = false;\n        for (int i = 0; i < lB.length; i++) {\n            if (!Double.isInfinite(lB[i]) ||\n                !Double.isInfinite(uB[i])) {\n                hasFiniteBounds = true;\n                break;\n            }\n        }\n        // Checks whether there is at least one infinite bound value.\n        boolean hasInfiniteBounds = false;\n        if (hasFiniteBounds) {\n            for (int i = 0; i < lB.length; i++) {\n                if (Double.isInfinite(lB[i]) ||\n                    Double.isInfinite(uB[i])) {\n                    hasInfiniteBounds = true;\n                    break;\n                }\n            }\n\n            if (hasInfiniteBounds) {\n                // If there is at least one finite bound, none can be infinite,\n                // because mixed cases are not supported by the current code.\n                throw new MathUnsupportedOperationException();\n            } else {\n                // Convert API to internal handling of boundaries.\n                boundaries = new double[2][];\n                boundaries[0] = lB;\n                boundaries[1] = uB;\n\n                // Abort early if the normalization will overflow (cf. \"encode\" method).\n            }\n        } else {\n            // Convert API to internal handling of boundaries.\n            boundaries = null;\n        }\n\n        if (inputSigma != null) {\n            if (inputSigma.length != init.length) {\n                throw new DimensionMismatchException(inputSigma.length, init.length);\n            }\n            for (int i = 0; i < init.length; i++) {\n                if (inputSigma[i] < 0) {\n                    throw new NotPositiveException(inputSigma[i]);\n                }\n                if (boundaries != null) {\n                    if (inputSigma[i] > boundaries[1][i] - boundaries[0][i]) {\n                        throw new OutOfRangeException(inputSigma[i], 0, boundaries[1][i] - boundaries[0][i]);\n                    }\n                }\n            }\n        }\n    }", "initializeCMA": "    private void initializeCMA(double[] guess) {\n        if (lambda <= 0) {\n            lambda = 4 + (int) (3. * Math.log(dimension));\n        }\n        // initialize sigma\n        double[][] sigmaArray = new double[guess.length][1];\n        for (int i = 0; i < guess.length; i++) {\n            final double range =  (boundaries == null) ? 1.0 : boundaries[1][i] - boundaries[0][i];\n            sigmaArray[i][0]   = ((inputSigma == null) ? 0.3 : inputSigma[i]) / range;\n        }\n        RealMatrix insigma = new Array2DRowRealMatrix(sigmaArray, false);\n        sigma = max(insigma); // overall standard deviation\n\n        // initialize termination criteria\n        stopTolUpX = 1e3 * max(insigma);\n        stopTolX = 1e-11 * max(insigma);\n        stopTolFun = 1e-12;\n        stopTolHistFun = 1e-13;\n\n        // initialize selection strategy parameters\n        mu = lambda / 2; // number of parents/points for recombination\n        logMu2 = Math.log(mu + 0.5);\n        weights = log(sequence(1, mu, 1)).scalarMultiply(-1.).scalarAdd(logMu2);\n        double sumw = 0;\n        double sumwq = 0;\n        for (int i = 0; i < mu; i++) {\n            double w = weights.getEntry(i, 0);\n            sumw += w;\n            sumwq += w * w;\n        }\n        weights = weights.scalarMultiply(1. / sumw);\n        mueff = sumw * sumw / sumwq; // variance-effectiveness of sum w_i x_i\n\n        // initialize dynamic strategy parameters and constants\n        cc = (4. + mueff / dimension) /\n                (dimension + 4. + 2. * mueff / dimension);\n        cs = (mueff + 2.) / (dimension + mueff + 3.);\n        damps = (1. + 2. * Math.max(0, Math.sqrt((mueff - 1.) /\n                (dimension + 1.)) - 1.)) *\n                Math.max(0.3, 1. - dimension /\n                        (1e-6 + Math.min(maxIterations, getMaxEvaluations() /\n                                lambda))) + cs; // minor increment\n        ccov1 = 2. / ((dimension + 1.3) * (dimension + 1.3) + mueff);\n        ccovmu = Math.min(1 - ccov1, 2. * (mueff - 2. + 1. / mueff) /\n                ((dimension + 2.) * (dimension + 2.) + mueff));\n        ccov1Sep = Math.min(1, ccov1 * (dimension + 1.5) / 3.);\n        ccovmuSep = Math.min(1 - ccov1, ccovmu * (dimension + 1.5) / 3.);\n        chiN = Math.sqrt(dimension) *\n                (1. - 1. / (4. * dimension) + 1 / (21. * dimension * dimension));\n        // intialize CMA internal values - updated each generation\n        xmean = MatrixUtils.createColumnRealMatrix(guess); // objective\n                                                           // variables\n        diagD = insigma.scalarMultiply(1. / sigma);\n        diagC = square(diagD);\n        pc = zeros(dimension, 1); // evolution paths for C and sigma\n        ps = zeros(dimension, 1); // B defines the coordinate system\n        normps = ps.getFrobeniusNorm();\n\n        B = eye(dimension, dimension);\n        D = ones(dimension, 1); // diagonal D defines the scaling\n        BD = times(B, repmat(diagD.transpose(), dimension, 1));\n        C = B.multiply(diag(square(D)).multiply(B.transpose())); // covariance\n        historySize = 10 + (int) (3. * 10. * dimension / lambda);\n        fitnessHistory = new double[historySize]; // history of fitness values\n        for (int i = 0; i < historySize; i++) {\n            fitnessHistory[i] = Double.MAX_VALUE;\n        }\n    }", "updateEvolutionPaths": "    private boolean updateEvolutionPaths(RealMatrix zmean, RealMatrix xold) {\n        ps = ps.scalarMultiply(1. - cs).add(\n                B.multiply(zmean).scalarMultiply(\n                        Math.sqrt(cs * (2. - cs) * mueff)));\n        normps = ps.getFrobeniusNorm();\n        boolean hsig = normps /\n            Math.sqrt(1. - Math.pow(1. - cs, 2. * iterations)) /\n                chiN < 1.4 + 2. / (dimension + 1.);\n        pc = pc.scalarMultiply(1. - cc);\n        if (hsig) {\n            pc = pc.add(xmean.subtract(xold).scalarMultiply(\n                    Math.sqrt(cc * (2. - cc) * mueff) / sigma));\n        }\n        return hsig;\n    }", "updateCovarianceDiagonalOnly": "    private void updateCovarianceDiagonalOnly(boolean hsig,\n                                              final RealMatrix bestArz,\n                                              final RealMatrix xold) {\n        // minor correction if hsig==false\n        double oldFac = hsig ? 0 : ccov1Sep * cc * (2. - cc);\n        oldFac += 1. - ccov1Sep - ccovmuSep;\n        diagC = diagC.scalarMultiply(oldFac) // regard old matrix\n                // plus rank one update\n                .add(square(pc).scalarMultiply(ccov1Sep))\n                // plus rank mu update\n                .add((times(diagC, square(bestArz).multiply(weights)))\n                        .scalarMultiply(ccovmuSep));\n        diagD = sqrt(diagC); // replaces eig(C)\n        if (diagonalOnly > 1 && iterations > diagonalOnly) {\n            // full covariance matrix from now on\n            diagonalOnly = 0;\n            B = eye(dimension, dimension);\n            BD = diag(diagD);\n            C = diag(diagC);\n        }\n    }", "updateCovariance": "    private void updateCovariance(boolean hsig, final RealMatrix bestArx,\n            final RealMatrix arz, final int[] arindex, final RealMatrix xold) {\n        double negccov = 0;\n        if (ccov1 + ccovmu > 0) {\n            RealMatrix arpos = bestArx.subtract(repmat(xold, 1, mu))\n                    .scalarMultiply(1. / sigma); // mu difference vectors\n            RealMatrix roneu = pc.multiply(pc.transpose())\n                    .scalarMultiply(ccov1); // rank one update\n            // minor correction if hsig==false\n            double oldFac = hsig ? 0 : ccov1 * cc * (2. - cc);\n            oldFac += 1. - ccov1 - ccovmu;\n            if (isActiveCMA) {\n                // Adapt covariance matrix C active CMA\n                negccov = (1. - ccovmu) * 0.25 * mueff /\n                (Math.pow(dimension + 2., 1.5) + 2. * mueff);\n                double negminresidualvariance = 0.66;\n                // keep at least 0.66 in all directions, small popsize are most\n                // critical\n                double negalphaold = 0.5; // where to make up for the variance\n                                          // loss,\n                // prepare vectors, compute negative updating matrix Cneg\n                int[] arReverseIndex = reverse(arindex);\n                RealMatrix arzneg\n                    = selectColumns(arz, MathArrays.copyOf(arReverseIndex, mu));\n                RealMatrix arnorms = sqrt(sumRows(square(arzneg)));\n                int[] idxnorms = sortedIndices(arnorms.getRow(0));\n                RealMatrix arnormsSorted = selectColumns(arnorms, idxnorms);\n                int[] idxReverse = reverse(idxnorms);\n                RealMatrix arnormsReverse = selectColumns(arnorms, idxReverse);\n                arnorms = divide(arnormsReverse, arnormsSorted);\n                int[] idxInv = inverse(idxnorms);\n                RealMatrix arnormsInv = selectColumns(arnorms, idxInv);\n                // check and set learning rate negccov\n                double negcovMax = (1. - negminresidualvariance) /\n                        square(arnormsInv).multiply(weights).getEntry(0, 0);\n                if (negccov > negcovMax) {\n                    negccov = negcovMax;\n                }\n                arzneg = times(arzneg, repmat(arnormsInv, dimension, 1));\n                RealMatrix artmp = BD.multiply(arzneg);\n                RealMatrix Cneg = artmp.multiply(diag(weights)).multiply(\n                        artmp.transpose());\n                oldFac += negalphaold * negccov;\n                C = C.scalarMultiply(oldFac)\n                        // regard old matrix\n                        .add(roneu)\n                        // plus rank one update\n                        .add(arpos.scalarMultiply(\n                                // plus rank mu update\n                                ccovmu + (1. - negalphaold) * negccov)\n                                .multiply(\n                                        times(repmat(weights, 1, dimension),\n                                                arpos.transpose())))\n                        .subtract(Cneg.scalarMultiply(negccov));\n            } else {\n                // Adapt covariance matrix C - nonactive\n                C = C.scalarMultiply(oldFac) // regard old matrix\n                        .add(roneu)\n                        // plus rank one update\n                        .add(arpos.scalarMultiply(ccovmu) // plus rank mu update\n                                .multiply(\n                                        times(repmat(weights, 1, dimension),\n                                                arpos.transpose())));\n            }\n        }\n        updateBD(negccov);\n    }", "push": "    private static void push(double[] vals, double val) {\n        for (int i = vals.length-1; i > 0; i--) {\n            vals[i] = vals[i-1];\n        }\n        vals[0] = val;\n    }", "sortedIndices": "    private int[] sortedIndices(final double[] doubles) {\n        DoubleIndex[] dis = new DoubleIndex[doubles.length];\n        for (int i = 0; i < doubles.length; i++) {\n            dis[i] = new DoubleIndex(doubles[i], i);\n        }\n        Arrays.sort(dis);\n        int[] indices = new int[doubles.length];\n        for (int i = 0; i < doubles.length; i++) {\n            indices[i] = dis[i].index;\n        }\n        return indices;\n    }", "equals": "        public boolean equals(Object other) {\n\n            if (this == other) {\n                return true;\n            }\n\n            if (other instanceof DoubleIndex) {\n                return Double.compare(value, ((DoubleIndex) other).value) == 0;\n            }\n\n            return false;\n\n        }", "encode": "        public double[] encode(final double[] x) {\n            if (boundaries == null) {\n                return x;\n            }\n            double[] res = new double[x.length];\n            for (int i = 0; i < x.length; i++) {\n                double diff = boundaries[1][i] - boundaries[0][i];\n                res[i] = (x[i] - boundaries[0][i]) / diff;\n            }\n            return res;\n        }", "repairAndDecode": "        public double[] repairAndDecode(final double[] x) {\n            return boundaries != null && isRepairMode ?\n                decode(repair(x)) :\n                decode(x);\n        }", "decode": "        public double[] decode(final double[] x) {\n            if (boundaries == null) {\n                return x;\n            }\n            double[] res = new double[x.length];\n            for (int i = 0; i < x.length; i++) {\n                double diff = boundaries[1][i] - boundaries[0][i];\n                res[i] = diff * x[i] + boundaries[0][i];\n            }\n            return res;\n        }", "value": "        public double value(final double[] point) {\n            double value;\n            if (boundaries != null && isRepairMode) {\n                double[] repaired = repair(point);\n                value = CMAESOptimizer.this\n                        .computeObjectiveValue(decode(repaired)) +\n                        penalty(point, repaired);\n            } else {\n                value = CMAESOptimizer.this\n                        .computeObjectiveValue(decode(point));\n            }\n            return isMinimize ? value : -value;\n        }", "isFeasible": "        public boolean isFeasible(final double[] x) {\n            if (boundaries == null) {\n                return true;\n            }\n            for (int i = 0; i < x.length; i++) {\n                if (x[i] < 0) {\n                    return false;\n                }\n                if (x[i] > 1.0) {\n                    return false;\n                }\n            }\n            return true;\n        }", "repair": "        private double[] repair(final double[] x) {\n            double[] repaired = new double[x.length];\n            for (int i = 0; i < x.length; i++) {\n                if (x[i] < 0) {\n                    repaired[i] = 0;\n                } else if (x[i] > 1.0) {\n                    repaired[i] = 1.0;\n                } else {\n                    repaired[i] = x[i];\n                }\n            }\n            return repaired;\n        }", "penalty": "        private double penalty(final double[] x, final double[] repaired) {\n            double penalty = 0;\n            for (int i = 0; i < x.length; i++) {\n                double diff = Math.abs(x[i] - repaired[i]);\n                penalty += diff * valueRange;\n            }\n            return isMinimize ? penalty : -penalty;\n        }", "log": "    private static RealMatrix log(final RealMatrix m) {\n        double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = Math.log(m.getEntry(r, c));\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }", "sqrt": "    private static RealMatrix sqrt(final RealMatrix m) {\n        double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = Math.sqrt(m.getEntry(r, c));\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }", "square": "    private static RealMatrix square(final RealMatrix m) {\n        double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                double e = m.getEntry(r, c);\n                d[r][c] = e * e;\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }", "times": "    private static RealMatrix times(final RealMatrix m, final RealMatrix n) {\n        double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = m.getEntry(r, c) * n.getEntry(r, c);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }", "divide": "    private static RealMatrix divide(final RealMatrix m, final RealMatrix n) {\n        double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = m.getEntry(r, c) / n.getEntry(r, c);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }", "triu": "    private static RealMatrix triu(final RealMatrix m, int k) {\n        double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = r <= c - k ? m.getEntry(r, c) : 0;\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }", "diag": "    private static RealMatrix diag(final RealMatrix m) {\n        if (m.getColumnDimension() == 1) {\n            double[][] d = new double[m.getRowDimension()][m.getRowDimension()];\n            for (int i = 0; i < m.getRowDimension(); i++) {\n                d[i][i] = m.getEntry(i, 0);\n            }\n            return new Array2DRowRealMatrix(d, false);\n        } else {\n            double[][] d = new double[m.getRowDimension()][1];\n            for (int i = 0; i < m.getColumnDimension(); i++) {\n                d[i][0] = m.getEntry(i, i);\n            }\n            return new Array2DRowRealMatrix(d, false);\n        }\n    }", "ones": "    private static RealMatrix ones(int n, int m) {\n        double[][] d = new double[n][m];\n        for (int r = 0; r < n; r++) {\n            Arrays.fill(d[r], 1.0);\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }", "eye": "    private static RealMatrix eye(int n, int m) {\n        double[][] d = new double[n][m];\n        for (int r = 0; r < n; r++) {\n            if (r < m) {\n                d[r][r] = 1;\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }", "zeros": "    private static RealMatrix zeros(int n, int m) {\n        return new Array2DRowRealMatrix(n, m);\n    }", "repmat": "    private static RealMatrix repmat(final RealMatrix mat, int n, int m) {\n        int rd = mat.getRowDimension();\n        int cd = mat.getColumnDimension();\n        double[][] d = new double[n * rd][m * cd];\n        for (int r = 0; r < n * rd; r++) {\n            for (int c = 0; c < m * cd; c++) {\n                d[r][c] = mat.getEntry(r % rd, c % cd);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }", "sequence": "    private static RealMatrix sequence(double start, double end, double step) {\n        int size = (int) ((end - start) / step + 1);\n        double[][] d = new double[size][1];\n        double value = start;\n        for (int r = 0; r < size; r++) {\n            d[r][0] = value;\n            value += step;\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }", "max": "    private static double max(final double[] m) {\n        double max = -Double.MAX_VALUE;\n        for (int r = 0; r < m.length; r++) {\n            if (max < m[r]) {\n                max = m[r];\n            }\n        }\n        return max;\n    }", "min": "    private static double min(final double[] m) {\n        double min = Double.MAX_VALUE;\n        for (int r = 0; r < m.length; r++) {\n            if (min > m[r]) {\n                min = m[r];\n            }\n        }\n        return min;\n    }", "inverse": "    private static int[] inverse(final int[] indices) {\n        int[] inverse = new int[indices.length];\n        for (int i = 0; i < indices.length; i++) {\n            inverse[indices[i]] = i;\n        }\n        return inverse;\n    }", "reverse": "    private static int[] reverse(final int[] indices) {\n        int[] reverse = new int[indices.length];\n        for (int i = 0; i < indices.length; i++) {\n            reverse[i] = indices[indices.length - i - 1];\n        }\n        return reverse;\n    }", "randn": "    private double[] randn(int size) {\n        double[] randn = new double[size];\n        for (int i = 0; i < size; i++) {\n            randn[i] = random.nextGaussian();\n        }\n        return randn;\n    }", "randn1": "    private RealMatrix randn1(int size, int popSize) {\n        double[][] d = new double[size][popSize];\n        for (int r = 0; r < size; r++) {\n            for (int c = 0; c < popSize; c++) {\n                d[r][c] = random.nextGaussian();\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }"}