{"TarArchiveInputStream": "public class TarArchiveInputStream extends ArchiveInputStream {\n\n    private static final int SMALL_BUFFER_SIZE = 256;\n\n    private final byte[] SMALL_BUF = new byte[SMALL_BUFFER_SIZE];\n\n    /** The size the TAR header */\n    private final int recordSize;\n\n    /** The size of a block */\n    private final int blockSize;\n\n    /** True if file has hit EOF */\n    private boolean hasHitEOF;\n\n    /** Size of the current entry */\n    private long entrySize;\n\n    /** How far into the entry the stream is at */\n    private long entryOffset;\n\n    /** An input stream to read from */\n    private final InputStream is;\n\n    /** The meta-data about the current entry */\n    private TarArchiveEntry currEntry;\n\n    /** The encoding of the file */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     */\n    public TarArchiveInputStream(InputStream is) {\n         //The specific code has been omitted, but there is no error\n        }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, String encoding) {\n         //The specific code has been omitted, but there is no error\n        }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize) {\n         //The specific code has been omitted, but there is no error\n        }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize,\n                                 String encoding) {\n         //The specific code has been omitted, but there is no error\n        }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize) {\n         //The specific code has been omitted, but there is no error\n        }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize,\n                                 String encoding) {\n         //The specific code has been omitted, but there is no error\n        }\n\n    /**\n     * Closes this stream. Calls the TarBuffer's close() method.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        is.close();\n    }\n\n    /**\n     * Get the record size being used by this stream's buffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n         //The specific code has been omitted, but there is no error\n        }\n\n    /**\n     * Get the available data that can be read from the current\n     * entry in the archive. This does not indicate how much data\n     * is left in the entire archive, only in the current entry.\n     * This value is determined from the entry's size header field\n     * and the amount of data already read from the current entry.\n     * Integer.MAX_VALUE is returned in case more than Integer.MAX_VALUE\n     * bytes are left in the current entry in the archive.\n     *\n     * @return The number of available bytes for the current entry.\n     * @throws IOException for signature\n     */\n    @Override\n    public int available() throws IOException {\n        if (entrySize - entryOffset > Integer.MAX_VALUE) {\n         //The specific code has been omitted, but there is no error\n        }\n        return (int) (entrySize - entryOffset);\n    }\n\n    \n    /**\n     * Skips over and discards <code>n</code> bytes of data from this input\n     * stream. The <code>skip</code> method may, for a variety of reasons, end\n     * up skipping over some smaller number of bytes, possibly <code>0</code>.\n     * This may result from any of a number of conditions; reaching end of file\n     * or end of entry before <code>n</code> bytes have been skipped; are only\n     * two possibilities. The actual number of bytes skipped is returned. If\n     * <code>n</code> is negative, no bytes are skipped.\n     * \n     * \n     * @param n\n     *            the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @exception IOException\n     *                if some other I/O error occurs.\n     */\n    @Override\n    public long skip(final long n) throws IOException {\n        if (n <= 0) {\n         //The specific code has been omitted, but there is no error\n        }\n\n        final long available = entrySize - entryOffset;\n        final long skipped = is.skip(Math.min(n, available)); \n        count(skipped);\n        entryOffset += skipped;\n        return skipped;\n    }\n\n    /**\n     * Since we do not support marking just yet, we return false.\n     *\n     * @return False.\n     */\n    @Override\n    public boolean markSupported() {\n         //The specific code has been omitted, but there is no error\n        }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     *\n     * @param markLimit The limit to mark.\n     */\n    @Override\n    public void mark(int markLimit) {\n         //The specific code has been omitted, but there is no error\n        }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     */\n    @Override\n    public synchronized void reset() {\n         //The specific code has been omitted, but there is no error\n        }\n\n    /**\n     * Get the next entry in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry, and read the header and instantiate a new\n     * TarEntry from the header bytes and return that entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next TarEntry in the archive, or null.\n     * @throws IOException on error\n     */\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n         //The specific code has been omitted, but there is no error\n        }\n\n        if (currEntry != null) {\n         //The specific code has been omitted, but there is no error\n        }\n\n        byte[] headerBuf = getRecord();\n\n        if (headerBuf == null) {\n         //The specific code has been omitted, but there is no error\n        }\n\n        try {\n            currEntry = new TarArchiveEntry(headerBuf, zipEncoding);\n        } catch (IllegalArgumentException e) {\n         //The specific code has been omitted, but there is no error\n        }\n\n        entryOffset = 0;\n        entrySize = currEntry.getSize();\n\n        if (currEntry.isGNULongLinkEntry()) {\n            byte[] longLinkData = getLongNameData();\n            if (longLinkData == null) {\n         //The specific code has been omitted, but there is no error\n        }\n            currEntry.setLinkName(zipEncoding.decode(longLinkData));\n        }\n\n        if (currEntry.isGNULongNameEntry()) {\n            byte[] longNameData = getLongNameData();\n            if (longNameData == null) {\n         //The specific code has been omitted, but there is no error\n        }\n            currEntry.setName(zipEncoding.decode(longNameData));\n        }\n\n        if (currEntry.isPaxHeader()){ // Process Pax headers\n            paxHeaders();\n        }\n\n        if (currEntry.isGNUSparse()){ // Process sparse files\n            readGNUSparse();\n        }\n\n        // If the size of the next element in the archive has changed\n        // due to a new size being reported in the posix header\n        // information, we update entrySize here so that it contains\n        // the correct value.\n        entrySize = currEntry.getSize();\n\n        return currEntry;\n    }\n    \n    /**\n     * The last record block should be written at the full size, so skip any\n     * additional space used to fill a record after an entry\n     */\n    private void skipRecordPadding() throws IOException {\n        if (this.entrySize > 0 && this.entrySize % this.recordSize != 0) {\n         //The specific code has been omitted, but there is no error\n        }\n    }\n\n    /**\n     * Get the next entry in this tar archive as longname data.\n     *\n     * @return The next entry in the archive as longname data, or null.\n     * @throws IOException on error\n     */\n    protected byte[] getLongNameData() throws IOException {\n        // read in the name\n        ByteArrayOutputStream longName = new ByteArrayOutputStream();\n        int length = 0;\n        while ((length = read(SMALL_BUF)) >= 0) {\n            longName.write(SMALL_BUF, 0, length);\n        }\n        getNextEntry();\n        if (currEntry == null) {\n         //The specific code has been omitted, but there is no error\n        }\n        byte[] longNameData = longName.toByteArray();\n        // remove trailing null terminator(s)\n        length = longNameData.length;\n        while (length > 0 && longNameData[length - 1] == 0) {\n         //The specific code has been omitted, but there is no error\n        }\n        if (length != longNameData.length) {\n         //The specific code has been omitted, but there is no error\n        }\n        return longNameData;\n    }\n\n    /**\n     * Get the next record in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry.\n     *\n     * <p>If there are no more entries in the archive, null will be\n     * returned to indicate that the end of the archive has been\n     * reached.  At the same time the {@code hasHitEOF} marker will be\n     * set to true.</p>\n     *\n     * @return The next header in the archive, or null.\n     * @throws IOException on error\n     */\n    private byte[] getRecord() throws IOException {\n        byte[] headerBuf = readRecord();\n        hasHitEOF = isEOFRecord(headerBuf);\n        if (hasHitEOF && headerBuf != null) {\n         //The specific code has been omitted, but there is no error\n        }\n        return headerBuf;\n    }\n\n    /**\n     * Determine if an archive record indicate End of Archive. End of\n     * archive is indicated by a record that consists entirely of null bytes.\n     *\n     * @param record The record data to check.\n     * @return true if the record data is an End of Archive\n     */\n    protected boolean isEOFRecord(byte[] record) {\n         //The specific code has been omitted, but there is no error\n        }\n    \n    /**\n     * Read a record from the input stream and return the data.\n     *\n     * @return The record data or null if EOF has been hit.\n     * @throws IOException on error\n     */\n    protected byte[] readRecord() throws IOException {\n\n        byte[] record = new byte[recordSize];\n\n        int readNow = IOUtils.readFully(is, record);\n        count(readNow);\n        if (readNow != recordSize) {\n         //The specific code has been omitted, but there is no error\n        }\n\n        return record;\n    }\n\n    private void paxHeaders() throws IOException{\n        Map<String, String> headers = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n        applyPaxHeadersToCurrentEntry(headers);\n    }\n\n    Map<String, String> parsePaxHeaders(InputStream i) throws IOException {\n        Map<String, String> headers = new HashMap<String, String>();\n        // Format is \"length keyword=value\\n\";\n        while(true){\n         //The specific code has been omitted, but there is no error\n        }\n        return headers;\n    }\n\n    private void applyPaxHeadersToCurrentEntry(Map<String, String> headers) {\n         //The specific code has been omitted, but there is no error\n        }\n\n    /**\n     * Adds the sparse chunks from the current entry to the sparse chunks,\n     * including any additional sparse entries following the current entry.\n     *\n     * @throws IOException on error\n     *\n     * @todo Sparse files get not yet really processed.\n     */\n    private void readGNUSparse() throws IOException {\n        /* we do not really process sparse files yet\n        sparses = new ArrayList();\n        sparses.addAll(currEntry.getSparses());\n        */\n        if (currEntry.isExtended()) {\n            TarArchiveSparseEntry entry;\n            do {\n                byte[] headerBuf = getRecord();\n                if (headerBuf == null) {\n         //The specific code has been omitted, but there is no error\n        }\n                entry = new TarArchiveSparseEntry(headerBuf);\n                /* we do not really process sparse files yet\n                sparses.addAll(entry.getSparses());\n                */\n            } while (entry.isExtended());\n        }\n    }\n\n    /**\n     * Returns the next Archive Entry in this Stream.\n     *\n     * @return the next entry,\n     *         or {@code null} if there are no more entries\n     * @throws IOException if the next entry could not be read\n     */\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextTarEntry();\n    }\n    \n    /**\n     * Tries to read the next record rewinding the stream if it is not a EOF record.\n     *\n     * <p>This is meant to protect against cases where a tar\n     * implementation has written only one EOF record when two are\n     * expected.  Actually this won't help since a non-conforming\n     * implementation likely won't fill full blocks consisting of - by\n     * default - ten records either so we probably have already read\n     * beyond the archive anyway.</p>\n     */\n    private void tryToConsumeSecondEOFRecord() throws IOException {\n        boolean shouldReset = true;\n        boolean marked = is.markSupported();\n        if (marked) {\n         //The specific code has been omitted, but there is no error\n        }\n        try {\n            shouldReset = !isEOFRecord(readRecord());\n        } finally {\n            if (shouldReset && marked) {\n         //The specific code has been omitted, but there is no error\n        }\n        }\n    }\n\n    /**\n     * Reads bytes from the current tar archive entry.\n     *\n     * This method is aware of the boundaries of the current\n     * entry in the archive and will deal with them as if they\n     * were this stream's start and EOF.\n     *\n     * @param buf The buffer into which to place bytes read.\n     * @param offset The offset at which to place bytes read.\n     * @param numToRead The number of bytes to read.\n     * @return The number of bytes read, or -1 at EOF.\n     * @throws IOException on error\n     */\n    @Override\n    public int read(byte[] buf, int offset, int numToRead) throws IOException {\n    \tint totalRead = 0;\n\n        if (hasHitEOF || entryOffset >= entrySize) {\n         //The specific code has been omitted, but there is no error\n        }\n\n        if (currEntry == null) {\n         //The specific code has been omitted, but there is no error\n        }\n\n        numToRead = Math.min(numToRead, available());\n        \n        totalRead = is.read(buf, offset, numToRead);\n        \n        if (totalRead == -1) {\n         //The specific code has been omitted, but there is no error\n        } else {\n            count(totalRead);\n            entryOffset += totalRead;\n        }\n\n        return totalRead;\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if the current entry is a sparse file.</p>\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n         //The specific code has been omitted, but there is no error\n        }\n\n    /**\n     * Get the current TAR Archive Entry that this input stream is processing\n     * \n     * @return The current Archive Entry\n     */\n    public TarArchiveEntry getCurrentEntry() {\n         //The specific code has been omitted, but there is no error\n        }\n\n    protected final void setCurrentEntry(TarArchiveEntry e) {\n         //The specific code has been omitted, but there is no error\n        }\n\n    protected final boolean isAtEOF() {\n         //The specific code has been omitted, but there is no error\n        }\n\n    protected final void setAtEOF(boolean b) {\n         //The specific code has been omitted, but there is no error\n        }\n\n    /**\n     * This method is invoked once the end of the archive is hit, it\n     * tries to consume the remaining bytes under the assumption that\n     * the tool creating this archive has padded the last block.\n     */\n    private void consumeRemainderOfLastBlock() throws IOException {\n        long bytesReadOfLastBlock = getBytesRead() % blockSize;\n        if (bytesReadOfLastBlock > 0) {\n         //The specific code has been omitted, but there is no error\n        }\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a tar file.\n     *\n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a tar archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n         //The specific code has been omitted, but there is no error\n        }\n\n}"}